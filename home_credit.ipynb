{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MbeyZ2G1wIN"
      },
      "outputs": [],
      "source": [
        "# STEP 1: EDA singkat\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/application_train.csv')\n",
        "\n",
        "# 1) Basic info (panggil saja agar terlihat tipe kolom & ukuran)\n",
        "print(\"=== SHAPE ===\")\n",
        "print(df.shape)\n",
        "print(\"\\n=== DTYPE COUNTS ===\")\n",
        "print(df.dtypes.value_counts())\n",
        "\n",
        "# 2) Top 20 kolom dengan missing value (persentase)\n",
        "print(\"\\n=== TOP 20 MISSING (%) ===\")\n",
        "print((df.isnull().mean().sort_values(ascending=False).head(20) * 100).round(2))\n",
        "\n",
        "# 3) Target distribution\n",
        "print(\"\\n=== TARGET DISTRIBUTION ===\")\n",
        "print(df['TARGET'].value_counts().to_frame('count'))\n",
        "print((df['TARGET'].value_counts(normalize=True) * 100).round(2).astype(str) + '%')\n",
        "\n",
        "# 4) Quick numeric summary for key financial cols if present\n",
        "cols_to_check = ['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','DAYS_BIRTH','DAYS_EMPLOYED',\n",
        "                 'EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']\n",
        "present = [c for c in cols_to_check if c in df.columns]\n",
        "print(\"\\n=== DESCRIBE FOR KEY COLUMNS ===\")\n",
        "print(df[present].describe().T)\n",
        "\n",
        "# 5) Create AGE (years) from DAYS_BIRTH for convenience and show simple groups\n",
        "if 'DAYS_BIRTH' in df.columns:\n",
        "    df['AGE_YEARS'] = (-df['DAYS_BIRTH'] / 365).round().astype(int)\n",
        "    print(\"\\n=== AGE BUCKET COUNTS ===\")\n",
        "    print(pd.cut(df['AGE_YEARS'], bins=[18,25,35,45,55,65,100]).value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: detail missing & sample values for high-missing columns\n",
        "# list kolom dengan missing > 20%\n",
        "high_miss = (df.isnull().mean() > 0.20)\n",
        "high_miss_cols = df.columns[high_miss].tolist()\n",
        "print(\"Columns with >20% missing:\", len(high_miss_cols))\n",
        "print(high_miss_cols[:30])   # tampilkan 30 pertama kalau banyak\n",
        "\n",
        "# show sample values for some categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(\"\\nSample categorical columns (count):\", len(cat_cols))\n",
        "print(cat_cols[:10])\n",
        "for c in cat_cols[:10]:\n",
        "    print(f\"--- Unique values for {c} (top 10) ---\")\n",
        "    print(df[c].value_counts(dropna=False).head(10))"
      ],
      "metadata": {
        "id": "vut5-UDO3RRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: imbalance + per-feature mean by TARGET for a few features\n",
        "print(\"Target balance (counts):\")\n",
        "print(df['TARGET'].value_counts())\n",
        "print(\"Target balance (percent):\")\n",
        "print((df['TARGET'].value_counts(normalize=True)*100).round(2))\n",
        "\n",
        "# Compare means for some numeric features by TARGET\n",
        "num_feats = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "check_feats = ['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AGE_YEARS','EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']\n",
        "check_feats = [c for c in check_feats if c in num_feats]\n",
        "print(\"\\nMean of some features by TARGET:\")\n",
        "print(df.groupby('TARGET')[check_feats].median().T)"
      ],
      "metadata": {
        "id": "lIYXljN03aUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Quick plots (histogram + boxplot by TARGET). Run in Colab to see plots.\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(df['AMT_INCOME_TOTAL'].clip(upper=df['AMT_INCOME_TOTAL'].quantile(0.99)), bins=60, kde=False)\n",
        "plt.title('AMT_INCOME_TOTAL (capped at 99th pct)')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.boxplot(x='TARGET', y='AMT_CREDIT', data=df[df['AMT_CREDIT'] < df['AMT_CREDIT'].quantile(0.99)])\n",
        "plt.title('AMT_CREDIT by TARGET (capped)')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.kdeplot(df.loc[df['TARGET']==0,'AGE_YEARS'], label='no default')\n",
        "sns.kdeplot(df.loc[df['TARGET']==1,'AGE_YEARS'], label='default')\n",
        "plt.title('AGE distribution by TARGET')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "83-iyD9B3eg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: preprocessing minimal & split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# keep reasonable feature set to avoid memory explosion (drop ID + text)\n",
        "drop_cols = [c for c in ['SK_ID_CURR'] if c in df.columns]\n",
        "X = df.drop(columns=drop_cols + ['TARGET'], errors='ignore')\n",
        "y = df['TARGET'].astype(int)\n",
        "\n",
        "# Simple encoding for categorical: one-hot for low-cardinality, else drop high-card\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "# keep only categories with <=50 unique values to one-hot encode (avoid huge dim)\n",
        "small_card = [c for c in cat_cols if X[c].nunique() <= 50]\n",
        "X = pd.get_dummies(X, columns=small_card, drop_first=True)\n",
        "\n",
        "# Drop remaining high-cardinality categorical columns (those not in small_card)\n",
        "high_card_cols = [c for c in cat_cols if c not in small_card]\n",
        "X = X.drop(columns=high_card_cols, errors='ignore')\n",
        "\n",
        "# Fill remaining numeric missing with median\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "# Train-test split (80/20 stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "print(\"Train TARGET balance:\", y_train.value_counts(normalize=True).round(3))"
      ],
      "metadata": {
        "id": "3jf6KN533jDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Logistic Regression baseline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, classification_report, RocCurveDisplay\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=-1)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_prob_log = logreg.predict_proba(X_test)[:,1]\n",
        "y_pred_log = logreg.predict(X_test)\n",
        "\n",
        "print(\"LogReg AUC:\", round(roc_auc_score(y_test, y_prob_log),4))\n",
        "print(\"\\nClassification report (threshold 0.5):\")\n",
        "print(classification_report(y_test, y_pred_log))\n",
        "RocCurveDisplay.from_estimator(logreg, X_test, y_test)"
      ],
      "metadata": {
        "id": "NR3gZgww37zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: XGBoost\n",
        "!pip install -q xgboost\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=400, learning_rate=0.05, max_depth=4, subsample=0.8,\n",
        "    colsample_bytree=0.8, random_state=42, use_label_encoder=False, eval_metric='logloss', n_jobs=-1\n",
        ")\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "y_prob_xgb = xgb_clf.predict_proba(X_test)[:,1]\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "print(\"XGBoost AUC:\", round(roc_auc_score(y_test, y_prob_xgb),4))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "RocCurveDisplay.from_estimator(xgb_clf, X_test, y_test)"
      ],
      "metadata": {
        "id": "Y6eiw4DD447J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: ROC-AUC plot comparison\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr_log, tpr_log, _ = roc_curve(y_test, y_prob_log)\n",
        "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr_log, tpr_log, label=f'LogReg AUC={roc_auc_score(y_test,y_prob_log):.4f}')\n",
        "plt.plot(fpr_xgb, tpr_xgb, label=f'XGB AUC={roc_auc_score(y_test,y_prob_xgb):.4f}')\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Comparison'); plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xPdCiYF35I6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9: quick automatic insights\n",
        "# 1) Feature importance from XGBoost (top 10)\n",
        "fi = pd.Series(xgb_clf.feature_importances_, index=X_train.columns).sort_values(ascending=False).head(10)\n",
        "print(\"Top 10 feature importances (XGBoost):\")\n",
        "print(fi)\n",
        "\n",
        "# 2) Risk concentration: proportion of defaults in top decile of predicted risk\n",
        "X_test_copy = X_test.copy()\n",
        "X_test_copy['y_true'] = y_test.values\n",
        "X_test_copy['y_score'] = y_prob_xgb\n",
        "top_decile = X_test_copy['y_score'].quantile(0.9)\n",
        "cohort = X_test_copy[X_test_copy['y_score'] >= top_decile]\n",
        "print(\"\\nTop decile size:\", cohort.shape[0])\n",
        "print(\"Default rate in top decile:\", cohort['y_true'].mean())\n",
        "print(\"Overall default rate:\", y_test.mean())"
      ],
      "metadata": {
        "id": "9zwIF0OC5LvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}